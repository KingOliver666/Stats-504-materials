{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be56aa8",
   "metadata": {},
   "source": [
    "# This notebook demonstrates several methods for assessing the frequency\n",
    "# of extreme precipitation events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55748ad3",
   "metadata": {},
   "source": [
    "# For reference, a paper using extreme value techniques to study rainfall in Brazil:\n",
    "# https://link.springer.com/article/10.1007/s42452-020-03199-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eaed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import genpareto, genextreme\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gamma\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d5064",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tail_shape(z, p0=0.1, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Returns values x, p such that the slope of p on x estimates the\n",
    "    shape parameter (tail index) of a distribution with power-law\n",
    "    tails (if family='powerlaw'), or the rate parameter of a\n",
    "    distribution with exponential tails (if family='exponential').\n",
    "    The upper p0 fraction of the data in z are used to produce x, p.\n",
    "    The returned values in x are the order statistics of z in the\n",
    "    Exponential case, and the log order statistics of z in the Pareto\n",
    "    case. The returned values in p are derived from probability\n",
    "    points.  Scatterplot p against x to get a visualization of the\n",
    "    tail shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if family not in [\"exponential\", \"powerlaw\"]:\n",
    "        raise ValueError(\"Unknown family %s\" % family)\n",
    "\n",
    "    p = 1 - p0\n",
    "    z = np.asarray(z)\n",
    "    z.sort()\n",
    "    n = len(z)\n",
    "    m = int(np.around(p*n))\n",
    "    x = z[m-1:]\n",
    "    if family == \"powerlaw\":\n",
    "        x = np.log(x)\n",
    "    p = np.log(1 - np.arange(m, n+1) / (n+1))\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96266f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_tail_reg(x, ax, p0=0.99, family=\"powerlaw\"):\n",
    "    \"\"\"\n",
    "    Use least squares regression in the upper 'p0' fraction of the right\n",
    "    tail of a quantile plot to estimate the shape parameter, and add the\n",
    "    best fit line to the plot in axes 'ax'.\n",
    "    \"\"\"\n",
    "\n",
    "    x, p = tail_shape(x, p0=p0, family=family)\n",
    "\n",
    "    ax.plot(x, p, color=\"orange\")\n",
    "\n",
    "    # Estimate the tail index using a least squares fit to the order\n",
    "    # statistics.\n",
    "    alpha_hat = -np.cov(p, x)[0, 1] / np.var(x)\n",
    "    icept = p.mean() + alpha_hat*x.mean()\n",
    "\n",
    "    # The coordinates of the best-fit line\n",
    "    xx = np.asarray([x.min(), x.max()])\n",
    "    yy = icept - alpha_hat*xx\n",
    "\n",
    "    ax.plot(xx, yy, color=\"purple\")\n",
    "\n",
    "    return icept, alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221f85c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hill(z, k=200):\n",
    "    \"\"\"\n",
    "    Estimate the tail index of a distribution with poower law tails using Hill's\n",
    "    estimator, based on the upper k order statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.sort(z)\n",
    "    z = np.log(z[-k:])\n",
    "    return 1 / (z[1:] - z[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448b61e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_hill(z):\n",
    "    \"\"\"\n",
    "    Plot the Hill estimate of the tail index for a range\n",
    "    of values of the tuning parameter k.\n",
    "    \"\"\"\n",
    "\n",
    "    kv = np.arange(20, 501, 5)\n",
    "    ta = np.asarray([hill(z, k=k) for k in kv])\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"Hill estimate of the tail index\")\n",
    "    ax.plot(kv, ta)\n",
    "    ax.set_xlabel(\"k\", size=16)\n",
    "    ax.set_ylabel(\"Tail index estimate\", size=16)\n",
    "    pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c382c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_gev(x):\n",
    "    \"\"\"\n",
    "    Fit a generalized extreme value distribution (GEV) using maximum likelihood\n",
    "    estimation to the data in 'x'. Probability weighted moments are used to obtain\n",
    "    starting values:\n",
    "    https://www.stat.cmu.edu/technometrics/80-89/VOL-27-03/v2703251.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "\n",
    "    # Plotting positions\n",
    "    pp = np.arange(1/2, n + 1/2) / n\n",
    "\n",
    "    # Calculate the first three probability weighted moments\n",
    "    b = np.zeros(3)\n",
    "    for r in range(3):\n",
    "        b[r] = np.dot(pp**r, x) / n\n",
    "\n",
    "    # The PWM estimator of Hoskins et al.\n",
    "    c = (2*b[1] - b[0]) / (3*b[2] - b[0])  - np.log(2) / np.log(3)\n",
    "    shape = 7.8590*c + 2.9554*c**2\n",
    "    scale = (2*b[1] - b[0]) * shape / (gamma(1 + shape) * (1 - 1/2**shape))\n",
    "    loc = b[0] + scale*(gamma(1 + shape) - 1) / shape\n",
    "\n",
    "    # Get the MLE\n",
    "    x0 = np.asarray([shape, loc, scale])\n",
    "    def f(par):\n",
    "        shape, loc, scale = par\n",
    "        d = genextreme(shape, loc=loc, scale=scale)\n",
    "        return -d.logpdf(x).sum()\n",
    "\n",
    "    rr = minimize(f, x0, method=\"powell\")\n",
    "    shape, loc, scale = rr.x\n",
    "    return genextreme(shape, loc=loc, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e75b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def block_max(dx):\n",
    "    \"\"\"\n",
    "    Calculate the maximum precipitation value for each complete year,\n",
    "    and fit a generalized extreme value (GEV) distribution to the\n",
    "    data.  Then use the fitted model to calculate returns for a sequence\n",
    "    of time horizons, and create a QQ plot to assess goodness-of-fit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the annual maximum for all complete years\n",
    "    dx = dx.query(\"year > 1958 & year < 2023\")\n",
    "    yrmx = dx.groupby(\"year\")[\"PRCP\"].agg(np.max)\n",
    "\n",
    "    # Fit a generalized extreme value distribution to the block maxima.\n",
    "    gev = fit_gev(yrmx)\n",
    "\n",
    "    # m-observation returns\n",
    "    rr = pd.DataFrame({\"Years\": [10, 100, 500, 1000]})\n",
    "    rr[\"Return\"] = gev.ppf(1 - 1/rr.Years)\n",
    "    print(\"Returns based on GEV:\")\n",
    "    print(rr)\n",
    "\n",
    "    # Make a QQ plot to assess goodness of fit\n",
    "    z = np.sort(yrmx)\n",
    "    n = len(z)\n",
    "    pp = np.arange(1, n + 1) / (n + 1)\n",
    "    qq = gev.ppf(pp)\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.plot(qq, z)\n",
    "    ax.set_xlabel(\"GEV quantiles\")\n",
    "    ax.set_ylabel(\"Order statistics\")\n",
    "    ax.set_title(\"GEV fit to annual maxima\")\n",
    "    pdf.savefig()\n",
    "\n",
    "    return gev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af9bb8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gp_estimate(z):\n",
    "    \"\"\"\n",
    "    Estimate the parameters of a generalized Pareto distribution\n",
    "    using the empirical Bayes method of Zhang and Stephens.\n",
    "    https://www.jstor.org/stable/pdf/40586625.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.sort(z)\n",
    "    n = len(z)\n",
    "    xstar = z[int(np.round(n/4 + 0.5))]\n",
    "    m = np.ceil(20 + np.sqrt(n))\n",
    "    xmax = z.max()\n",
    "\n",
    "    jj = np.arange(1, m+1)\n",
    "    tgrid = 1/xmax + (1 - np.sqrt(m/(jj-0.5))) / (3 * xstar)\n",
    "\n",
    "    def profile(theta):\n",
    "        k = -np.log(1 - theta*z).mean()\n",
    "        return n*(np.log(theta/k) + k - 1)\n",
    "\n",
    "    ltg = np.asarray([profile(t) for t in tgrid])\n",
    "    ltg -= ltg.max()\n",
    "    Ltg = np.exp(ltg)\n",
    "    Ltg /= Ltg.sum()\n",
    "    theta_hat = np.dot(Ltg, tgrid)\n",
    "    k_hat = -np.log(1 - theta_hat*z).mean()\n",
    "    scale_hat = k_hat / theta_hat\n",
    "\n",
    "    return genpareto(-k_hat, scale=scale_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ff663",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eb_analysis(z):\n",
    "    \"\"\"\n",
    "    Fit a generalized Pareto model to the exceedances derived from z,\n",
    "    using empirical Bayes estimation, and create a QQ plot to assess\n",
    "    the goodness-of-fit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Exceedances\n",
    "    z = z[z > thresh] - thresh\n",
    "\n",
    "    # Empirical Bayes estimate of Zhang and Stephens.\n",
    "    eb = gp_estimate(z)\n",
    "\n",
    "    n = len(z)\n",
    "    pp = np.linspace(1/2, n - 1/2, n) / n # plotting positions\n",
    "    qq = eb.ppf(pp)\n",
    "    z = np.sort(z)\n",
    "\n",
    "    # QQ plot to show goodness of fit\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    ax.set_title(\"EB: shape=%.3f scale=%.3f\" % (eb.args[0], eb.kwds[\"scale\"]))\n",
    "    ax.plot(qq, z)\n",
    "    plt.xlabel(\"GP quantiles (EB)\", size=16)\n",
    "    plt.ylabel(\"Order statistics\", size=16)\n",
    "    pdf.savefig()\n",
    "\n",
    "    return eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a2cd8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_tails(z, p0, thresh, family):\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # Exceedances\n",
    "    z = z[z >= thresh]\n",
    "    z -= thresh\n",
    "\n",
    "    # The number of selected observations\n",
    "    m = int(np.around(p0*n))\n",
    "\n",
    "    xlabel = \"log Q(p)\" if family == \"powerlaw\" else \"Q(p)\"\n",
    "\n",
    "    plt.clf()\n",
    "    ax = plt.axes()\n",
    "    plt.grid(True)\n",
    "    icept, alpha = fit_tail_reg(z, ax, p0=p0, family=family)\n",
    "    ax.set_xlabel(xlabel, size=16)\n",
    "    ax.set_ylabel(\"log(1-p)\", size=16)\n",
    "    ti = \"%s model, threshold=%.1f, top %.1f%% (n=%d), alpha=%.3f\" %\\\n",
    "           (family.title(), thresh, 100*p0, m, alpha)\n",
    "    plt.title(ti)\n",
    "    pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275027c7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_gp_estimate(shape, scale, thresh, n=100000):\n",
    "    z = genpareto.rvs(shape, scale=scale, size=n)\n",
    "    z = z[z > thresh] - thresh\n",
    "    #shape_hill = hill(z)\n",
    "    eb = gp_estimate(z)\n",
    "    return eb#, shape_hill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c97be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mobs_return(z, mr, thresh, family=\"exponential\", gp=None):\n",
    "    \"\"\"\n",
    "    Calculate the m-observation returns for the data in z, using either\n",
    "    an exponential or generalized Pareto model.\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.asarray(z)\n",
    "    n = len(z)\n",
    "\n",
    "    # Select only extreme values and translate back to the origin\n",
    "    ix = np.flatnonzero(z >= thresh)\n",
    "    q = len(ix) / n # proportion of values exceeding the threshold\n",
    "    z = z[ix]\n",
    "    z -= thresh\n",
    "\n",
    "    pr = 1 - 1 / (q * mr)\n",
    "\n",
    "    if family == \"exponential\":\n",
    "        mn = z.mean()\n",
    "        print(\"Mean = %.2f\" % mn)\n",
    "        m0 = thresh - mn*np.log(1 - pr)\n",
    "    elif family == \"generalizedpareto\":\n",
    "        print(\"Shape=%.2f\" % eb.args[0])\n",
    "        print(\"Scale=%.2f\" % eb.kwds[\"scale\"])\n",
    "        m0 = thresh + gp.ppf(pr)\n",
    "    else:\n",
    "        raise ValueError(\"!!\")\n",
    "\n",
    "    return m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PdfPages(\"extremes_python.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to point to the location of the data, matching the path\n",
    "# name in get_data.py\n",
    "target_dir = \"/home/kshedden/data/Teaching/precip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific location to analyze.\n",
    "fname = \"USW00094847.csv\" # Detroit\n",
    "#fname = \"USW00012839.csv\" # Miami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(target_dir, fname + \".gz\"), parse_dates=[\"DATE\"],\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only care about these two variables.\n",
    "df = df[[\"DATE\", \"PRCP\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ea215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a year variable for block-maxima (GEV) analyses\n",
    "df[\"year\"] = df[\"DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee67781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert precipitation to millimeters\n",
    "df[\"PRCP\"] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9136df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this threshold for calculating exceedances\n",
    "thresh = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a time series\n",
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.plot(df[\"DATE\"], df[\"PRCP\"], \"-\", alpha=0.5)\n",
    "plt.xlabel(\"Date\", size=15)\n",
    "plt.ylabel(\"Precipitation (mm)\", size=15)\n",
    "pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd91224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a histogram\n",
    "plt.clf()\n",
    "plt.grid(True)\n",
    "plt.hist(df[\"PRCP\"])\n",
    "plt.xlabel(\"Precipitation (mm)\", size=13)\n",
    "plt.ylabel(\"Frequency\", size=14)\n",
    "pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a CDF\n",
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Cumulative probability\", size=15)\n",
    "pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a complementary CDF (ccdf, survival function)\n",
    "plt.clf()\n",
    "plt.grid(True)\n",
    "x = np.sort(df[\"PRCP\"])\n",
    "p = np.linspace(0, 1, len(x))\n",
    "plt.plot(x, 1 - p, \"-\")\n",
    "plt.xlabel(\"Precipitation (mm)\", size=15)\n",
    "plt.ylabel(\"Complementary cumulative probability\", size=14)\n",
    "pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d69455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile plots\n",
    "for family in [\"powerlaw\", \"exponential\"]:\n",
    "    for p0 in [0.5, 0.1, 0.05, 0.01]:\n",
    "        plot_tails(df[\"PRCP\"], p0, thresh, family)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a24eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hill(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4745bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generalized extreme value distributions to the block (annual) maxima.\n",
    "gev = block_max(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generalized Pareto models to the exceedances\n",
    "eb = eb_analysis(df[\"PRCP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate m-observation returns based on various models fit\n",
    "# to the 24 hour rainfall totals.\n",
    "yr = np.r_[1, 10, 100, 500, 1000]\n",
    "cfg = [(\"exponential\", None), (\"generalizedpareto\", eb)]\n",
    "for (f,g) in cfg:\n",
    "    print(\"\\nReturns based on %s:\" % f)\n",
    "    mr = mobs_return(df[\"PRCP\"], 365 * yr, thresh, family=f, gp=g)\n",
    "    rr = pd.DataFrame({\"Years\": yr, \"MR\": mr})\n",
    "    print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
